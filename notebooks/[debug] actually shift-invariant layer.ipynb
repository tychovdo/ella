{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "98950e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "e9f3e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample2(x):\n",
    "    x1 = x[:, :, ::2, ::2]\n",
    "    x2 = x[:, :, 1::2, ::2]\n",
    "    x3 = x[:, :, ::2, 1::2]\n",
    "    x4 = x[:, :, 1::2, 1::2]\n",
    "    \n",
    "    x1m, x2m, x3m, x4m = x1.max(), x2.max(), x3.max(), x4.max()\n",
    "    maxval = max(x1m, x2m, x3m, x4m)\n",
    "    if x1m == maxval:\n",
    "        return x1\n",
    "    elif x2m == maxval:\n",
    "        return x2\n",
    "    elif x3m == maxval:\n",
    "        return x3\n",
    "    else:\n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0bd37876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, h, w, stride=1):\n",
    "        super(BNConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1, padding_mode='circular')\n",
    "        self.stride = stride\n",
    "        self.activation = F.relu\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "        self.conv.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        convout = self.conv(x)\n",
    "        \n",
    "        if self.stride == 2:\n",
    "            convout = subsample2(convout)\n",
    "        elif self.stride > 2:\n",
    "            raise NotImplementedError(f\"Equivariance for stride {self.stride} not implemented yet\")\n",
    "        \n",
    "        return self.activation(convout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145eec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "7702df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_Conv(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10, alpha=1, h=32, w=32):\n",
    "        super(D_Conv, self).__init__()\n",
    "        modules = [BNConvBlock(in_ch, alpha, h=h, w=w, stride=1),\n",
    "                   BNConvBlock(alpha, 2*alpha, h=h, w=w, stride=2),\n",
    "                   BNConvBlock(2*alpha, 2*alpha, h=int(h/2), w=int(w/2), stride=1),\n",
    "                   BNConvBlock(2*alpha, 4*alpha, h=int(h/2), w=int(w/2), stride=2),\n",
    "                   BNConvBlock(4*alpha, 4*alpha, h=int(h/4), w=int(w/4), stride=1),\n",
    "                   BNConvBlock(4*alpha, 8*alpha, h=int(h/4), w=int(w/4), stride=2),\n",
    "                   BNConvBlock(8*alpha, 8*alpha, h=int(h/8), w=int(w/8), stride=1),\n",
    "                   BNConvBlock(8*alpha, 16*alpha,h=int(h/8), w=int(w/8), stride=2),\n",
    "                   BNConvBlock(16*alpha, 64*alpha,h=int(h/16), w=int(w/16), stride=2),\n",
    "                  ]\n",
    "        self.conv_net = nn.Sequential(*modules)\n",
    "        \n",
    "        self.activation = F.relu\n",
    "        self.final = nn.Conv2d(64*alpha, num_classes, 1, stride=1, padding=0, padding_mode='circular')\n",
    "        self.final.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        for layer in self.conv_net:\n",
    "            print(1, out.mean(), out.std())\n",
    "            out = layer(out)\n",
    "            print(2, out.mean(), out.std())\n",
    "            #plt.imshow(out[0, 0].detach().numpy())\n",
    "            \n",
    "        print(1, out.mean(), out.std())\n",
    "        out = self.final(out)\n",
    "        print(2, out.mean(), out.std())\n",
    "        out = out.view(*out.shape[:2])\n",
    "        print(3, out.mean(), out.std())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "8473b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "bc821d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = D_Conv(in_ch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "54f5dc15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0014) tensor(0.5051)\n",
      "tensor(0.0014) tensor(0.5051)\n"
     ]
    }
   ],
   "source": [
    "B, C, H, W = 16, 3, 32, 32\n",
    "\n",
    "u, v = 0, 16\n",
    "\n",
    "img = torch.randn((B, C, 16, 16)) * 1\n",
    "X = torch.zeros((B, C, H, W))\n",
    "X[:, :, u:u+16, u:u+16] = img\n",
    "\n",
    "X2 = torch.zeros((B, C, H, W))\n",
    "X2[:, :, v:v+16, u:u+16] = img\n",
    "\n",
    "print(X.mean(), X.std())\n",
    "print(X2.mean(), X2.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "386cd71d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(0.0014) tensor(0.5051)\n",
      "2 tensor(0.1752, grad_fn=<MeanBackward0>) tensor(0.5403, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1752, grad_fn=<MeanBackward0>) tensor(0.5403, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.1023, grad_fn=<MeanBackward0>) tensor(0.3889, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1023, grad_fn=<MeanBackward0>) tensor(0.3889, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.1036, grad_fn=<MeanBackward0>) tensor(0.2750, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1036, grad_fn=<MeanBackward0>) tensor(0.2750, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.2012, grad_fn=<MeanBackward0>) tensor(0.3802, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.2012, grad_fn=<MeanBackward0>) tensor(0.3802, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0816, grad_fn=<MeanBackward0>) tensor(0.1921, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0816, grad_fn=<MeanBackward0>) tensor(0.1921, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0941, grad_fn=<MeanBackward0>) tensor(0.1744, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0941, grad_fn=<MeanBackward0>) tensor(0.1744, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0864, grad_fn=<MeanBackward0>) tensor(0.1443, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0864, grad_fn=<MeanBackward0>) tensor(0.1443, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.1082, grad_fn=<MeanBackward0>) tensor(0.1406, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1082, grad_fn=<MeanBackward0>) tensor(0.1406, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0925, grad_fn=<MeanBackward0>) tensor(0.1544, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0925, grad_fn=<MeanBackward0>) tensor(0.1544, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0074, grad_fn=<MeanBackward0>) tensor(0.1044, grad_fn=<StdBackward0>)\n",
      "3 tensor(0.0074, grad_fn=<MeanBackward0>) tensor(0.1044, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0014) tensor(0.5051)\n",
      "2 tensor(0.1752, grad_fn=<MeanBackward0>) tensor(0.5403, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1752, grad_fn=<MeanBackward0>) tensor(0.5403, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.1023, grad_fn=<MeanBackward0>) tensor(0.3889, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1023, grad_fn=<MeanBackward0>) tensor(0.3889, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.1036, grad_fn=<MeanBackward0>) tensor(0.2750, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1036, grad_fn=<MeanBackward0>) tensor(0.2750, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.2012, grad_fn=<MeanBackward0>) tensor(0.3802, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.2012, grad_fn=<MeanBackward0>) tensor(0.3802, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0816, grad_fn=<MeanBackward0>) tensor(0.1921, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0816, grad_fn=<MeanBackward0>) tensor(0.1921, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0941, grad_fn=<MeanBackward0>) tensor(0.1744, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0941, grad_fn=<MeanBackward0>) tensor(0.1744, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0864, grad_fn=<MeanBackward0>) tensor(0.1443, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0864, grad_fn=<MeanBackward0>) tensor(0.1443, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.1082, grad_fn=<MeanBackward0>) tensor(0.1406, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.1082, grad_fn=<MeanBackward0>) tensor(0.1406, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0925, grad_fn=<MeanBackward0>) tensor(0.1544, grad_fn=<StdBackward0>)\n",
      "1 tensor(0.0925, grad_fn=<MeanBackward0>) tensor(0.1544, grad_fn=<StdBackward0>)\n",
      "2 tensor(0.0074, grad_fn=<MeanBackward0>) tensor(0.1044, grad_fn=<StdBackward0>)\n",
      "3 tensor(0.0074, grad_fn=<MeanBackward0>) tensor(0.1044, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = D_Conv(in_ch=C)\n",
    "Y = model(X)\n",
    "Y2 = model(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc538f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b45f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
